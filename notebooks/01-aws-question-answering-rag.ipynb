{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b985c5b5-1d65-4e4a-82d1-2dfc9768d97d",
   "metadata": {},
   "source": [
    "## Medical Question answering with Retrieval Augmented Generation design pattern. \n",
    "Use Python 3 (Data Science 3.0) kernel image and `ml.m5.xlarge` for this notebook.\n",
    "\n",
    "This includes generating embeddings of all existing documents, indexing them in a vector store. Then for every user query, generate local embeddings and search based on embedding distance. The search responses act as context to the LLM model to generate a output. \n",
    "\n",
    "Challenges:\n",
    "How to manage large document(s) that exceed the token limitHow to find the document(s) relevant to the question being asked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc84657b-0fff-4476-980d-d74894a74c27",
   "metadata": {},
   "source": [
    "## Key components\n",
    "\n",
    "LLM (Large Language Model): Falcon-40b-instruct available through Amazon SageMaker This model will be used to understand the document chunks and provide an answer in human friendly manner.\n",
    "\n",
    "Embeddings Model: GPT-J 6B available through Amazon SageMaker. This model will be used to generate a numerical representation of the textual documents.\n",
    "\n",
    "Vector Store: FAISS available through LangChainIn this notebook we are using this in-memory vector-store to store both the embeddings and the documents. In an enterprise context this could be replaced with a persistent store such as AWS OpenSearch, RDS Postgres with pgVector, ChromaDB, Pinecone or Weaviate.\n",
    "\n",
    "Index: VectorIndex The index helps to compare the input embedding and the document embeddings to find relevant document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87a992-1790-4d4e-8ffd-ab7c053156c1",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "To explain this architecture pattern we are using the documents from MedQA. These documents include medical textbooks such as:\n",
    "Pathology, Anatomy, Pharmacology and others. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0c4a8b-f1a1-4fc6-831c-3fdb522cf941",
   "metadata": {},
   "source": [
    "Download textbooks that are part of Q&A dataset MedQA released as part of Jin, Di, et al. \"What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams.\" arXiv preprint arXiv:2009.13081 (2020). \n",
    "\n",
    "More details are available here https://github.com/jind11/MedQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ed552-d458-4dd3-9b13-e3e997e10ade",
   "metadata": {},
   "source": [
    "* Data source : @article{jin2020disease,\n",
    "  title={What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams},\n",
    "  author={Jin, Di and Pan, Eileen and Oufattole, Nassim and Weng, Wei-Hung and Fang, Hanyi and Szolovits, Peter},\n",
    "  journal={arXiv preprint arXiv:2009.13081},\n",
    "  year={2020} }\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff5221-0349-4617-814d-98c79db7cfb1",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "Download the data from \n",
    "https://d1.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f98aef-1586-4ecf-a715-faff4007a013",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-26+deb11u1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      "unzip:  cannot find or open data_clean.zip, data_clean.zip.zip or data_clean.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "#Unzip the file\n",
    "!apt install unzip\n",
    "!unzip -q data_clean.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa4ada-a686-43de-bc90-0f4107f95ce1",
   "metadata": {},
   "source": [
    "##### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b71850-cf8d-4232-866e-53f7a8a685e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu==1.7.4 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6139ec9e-962f-44b4-94c1-9a778e4d2be4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.0.222 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf12933-564a-41a3-9a9e-c02a9437310e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "!pip install PyYAML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52706ec1-fd47-42d4-af0f-33f0a03f654d",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81eea5f6-50e3-4398-80eb-11b680d026b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging \n",
    "import boto3\n",
    "import yaml\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec6d42-db7a-4c4c-8322-95963806f987",
   "metadata": {},
   "source": [
    "##### Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcddd51c-9251-4428-9931-b2700a71142a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a81f78f-675d-4009-9228-8fa3cfc559b8",
   "metadata": {},
   "source": [
    "##### Log versions of dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75474334-8b19-4491-abb9-58468bc33329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using requests==2.31.0\n",
      "Using pyyaml==6.0\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Using requests=={requests.__version__}')\n",
    "logger.info(f'Using pyyaml=={yaml.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52e3b3f-f770-4b90-bc35-12cc0f793604",
   "metadata": {},
   "source": [
    "#### Setup essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a25a24c9-b504-45a0-888d-fe507b34402d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEXT_EMBEDDING_MODEL_ENDPOINT_NAME = 'jumpstart-dft-hf-textembedding-gpt-j-6b-fp16'\n",
    "TEXT_GENERATION_MODEL_ENDPOINT_NAME = 'jumpstart-dft-hf-llm-falcon-7b-instruct-bf16'\n",
    "\n",
    "REGION_NAME = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15360977-8631-4a21-a599-b91c91c8c893",
   "metadata": {},
   "source": [
    "#### Encode passages (chunks) using JumpStart's GPT-J text embedding model . We are specifically using only 1 of 20 textbooks from the dataset. It takes about 6 minutes to generate embeddings for one textbook (for example, Pathology). You can increase the number of textbooks indexed by adding sufficient time buffer for execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ed59e-7553-4e57-af5e-29d345a00028",
   "metadata": {},
   "source": [
    "In order to follow the RAG approach this notebook is using the LangChain framework where it has integrations with different services and tools that allow efficient building of patterns such as RAG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b9e0d3c-36ad-4d1c-b375-ea10e57ba10c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Obtaining dependency information for pypdf from https://files.pythonhosted.org/packages/e3/a8/daf130ed0e6ead60f99b037c360e3ed910a2cd0accdaf612589b8ba83187/pypdf-3.15.5-py3-none-any.whl.metadata\n",
      "  Downloading pypdf-3.15.5-py3-none-any.whl.metadata (7.1 kB)\n",
      "Downloading pypdf-3.15.5-py3-none-any.whl (272 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.6/272.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-3.15.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ad7c4b7-c6bd-40c2-b91e-0d6370fce251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pypdf\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"data/AWS_Well-Architected_Framework.pdf\")\n",
    "\n",
    "#loader = DirectoryLoader(\"./data/\", glob=\"*.pdf\", loader_cls=PDFLoader)\n",
    "\n",
    "documents = loader.load()\n",
    "# - in our testing Character split works better with this PDF data set\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 100,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad63c24e-190f-46ef-bfc7-2dac1112765e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='ArchivedAWS Well-Architected Framework\\nJuly 2020\\nThis whitepaper describes the AWS Well-Architected Framework. It provides guidance to help cus-\\ntomers apply best practices in the design, delivery, and maintenance of AWS environments. We address\\ngeneral design principles as well as specific best practices and guidance in ﬁve conceptual areas that\\nwe define as the pillars  of the Well-Architected Framework.This paper has been archived.\\nThe latest version is available at:\\nhttps://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html' metadata={'source': 'data/AWS_Well-Architected_Framework.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f4d6873-3ea9-4455-8b8d-cad845009a08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length among 97 documents loaded is 2259 characters.\n",
      "After the split we have 282 documents more than the original 97.\n",
      "Average length among 282 documents (after split) is 826 characters.\n"
     ]
    }
   ],
   "source": [
    "avg_doc_length = lambda documents: sum([len(doc.page_content) for doc in documents])//len(documents)\n",
    "avg_char_count_pre = avg_doc_length(documents)\n",
    "avg_char_count_post = avg_doc_length(docs)\n",
    "print(f'Average length among {len(documents)} documents loaded is {avg_char_count_pre} characters.')\n",
    "print(f'After the split we have {len(docs)} documents more than the original {len(documents)}.')\n",
    "print(f'Average length among {len(docs)} documents (after split) is {avg_char_count_post} characters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a82c416-9401-4b81-af41-f1ff334902d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from typing import Any, Dict, List, Optional\n",
    "from langchain.llms.sagemaker_endpoint import ContentHandlerBase\n",
    "\n",
    "\n",
    "class SagemakerEndpointEmbeddingsJumpStart(SagemakerEndpointEmbeddings):\n",
    "    def embed_documents(self, texts: List[str], chunk_size: int = 5) -> List[List[float]]:\n",
    "        \"\"\"Compute doc embeddings using a SageMaker Inference Endpoint.\n",
    "\n",
    "        Args:\n",
    "            texts: The list of texts to embed.\n",
    "            chunk_size: The chunk size defines how many input texts will\n",
    "                be grouped together as request. If None, will use the\n",
    "                chunk size specified by the class.\n",
    "\n",
    "        Returns:\n",
    "            List of embeddings, one for each text.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        _chunk_size = len(texts) if chunk_size > len(texts) else chunk_size\n",
    "\n",
    "        for i in range(0, len(texts), _chunk_size):\n",
    "            response = self._embedding_func(texts[i : i + _chunk_size])\n",
    "            print\n",
    "            results.extend(response)\n",
    "        return results\n",
    "\n",
    "\n",
    "class ContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs={}) -> bytes:\n",
    "        input_str = json.dumps({\"text_inputs\": prompt, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        embeddings = response_json[\"embedding\"]\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "sagemakerEndpointEmbeddingsJumpStart = SagemakerEndpointEmbeddingsJumpStart(\n",
    "    endpoint_name=TEXT_EMBEDDING_MODEL_ENDPOINT_NAME,\n",
    "    region_name=REGION_NAME,\n",
    "    content_handler=content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1ce0559-7ac9-429d-8527-6617759d3249",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArchivedAWS Well-Architected Framework\n",
      "July 2020\n",
      "This whitepaper describes the AWS Well-Architected Framework. It provides guidance to help cus-\n",
      "tomers apply best practices in the design, delivery, and maintenance of AWS environments. We address\n",
      "general design principles as well as specific best practices and guidance in ﬁve conceptual areas that\n",
      "we define as the pillars  of the Well-Architected Framework.This paper has been archived.\n",
      "The latest version is available at:\n",
      "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b4f2c08-3ba7-4e2b-8c70-179b794863b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding of a document chunk:  [-0.00153714  0.00214407  0.0035825  ...  0.00850618 -0.00149574\n",
      " -0.02181229]\n",
      "Size of the embedding:  (4096,)\n"
     ]
    }
   ],
   "source": [
    "sample_embedding = np.array(sagemakerEndpointEmbeddingsJumpStart.embed_query(docs[0].page_content))\n",
    "print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "print(\"Size of the embedding: \", sample_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8c7292-6931-4155-9e23-5c546801e868",
   "metadata": {},
   "source": [
    "Now create embeddings for the entire document set. Note for a single medical textbook, it takes about 6 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe662107-0401-42a5-8e02-b9045fb2a466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.contrib.concurrent import process_map\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "def generate_embeddings(x):\n",
    "    return (x, sagemakerEndpointEmbeddingsJumpStart.embed_query(x))\n",
    "    \n",
    "workers = 1 * cpu_count()\n",
    "\n",
    "texts = [i.page_content for i in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eba56c8f-be28-4268-b839-3aef2ec6d755",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec9badfc-2ca9-409e-acf9-416ddb294291",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47b09e213134e45950f75a61a9ec371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = process_map(generate_embeddings, texts, max_workers=workers, chunksize=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606ae3c-3ed2-4cd1-b9ba-40088614e0fa",
   "metadata": {},
   "source": [
    "Next, we insert the embeddings to the FAISS vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5462eaea-7c73-417e-afe1-dcf0b7cf3026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "faiss = FAISS.from_documents(docs[0:2], sagemakerEndpointEmbeddingsJumpStart)\n",
    "faiss.add_embeddings(data)\n",
    "faiss.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4fef5b-06cb-401a-812d-f4f1823398e9",
   "metadata": {},
   "source": [
    "Next we create user query to retrieve a response from vector search and LLM combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b05a412e-c6eb-4e68-a334-5318d503f8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What are the 5 pillars of well architected framework?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96620221-20d4-4559-990e-f9b2c4c9c1ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00698841, -0.02292958,  0.01051318, ..., -0.01012999,\n",
       "       -0.00661008, -0.001499  ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding = faiss.embedding_function(query)\n",
    "np.array(query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23f2d2ef-5c20-47a1-98c1-d789ee0452fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 documents are fetched which are relevant to the query.\n",
      "----\n",
      "## Document 1: can emerge that is driven by customer need. Technology leaders (such as a CTOs or\n",
      "development managers), carrying out Well-Architected reviews across all your work-\n",
      "loads will allow you to better understand the risks in your technology portfolio. Using\n",
      "this approach, you can identify themes across teams that your organization could ad-\n",
      "dress by mechanisms, training, or lunchtime talks where your principal engineers can\n",
      "share their thinking on specific areas with multiple teams.\n",
      "3Working backward is a fundamental part of our innovation process. We start with the customer and what\n",
      "they want, and let that define and guide our efforts.\n",
      "4.......\n",
      "---\n",
      "## Document 2: ternet scale. We prefer to use data to define best practice, but we also use subject\n",
      "matter experts, like principal engineers, to set them. As principal engineers see new\n",
      "best practices emerge, they work as a community to ensure that teams follow them.\n",
      "In time, these best practices are formalized into our internal review processes, as well\n",
      "as into mechanisms that enforce compliance. The Well-Architected Framework is the\n",
      "customer-facing implementation of our internal review process, where we have cod-\n",
      "ified our principal engineering thinking across ﬁeld roles, like Solutions Architecture\n",
      "and internal engineering teams. The Well-Architected Framework is a scalable mecha-\n",
      "nism that lets you take advantage of these learnings.\n",
      "By following the approach of a principal engineering community with distributed\n",
      "ownership of architecture, we believe that a Well-Architected enterprise architecture\n",
      "can emerge that is driven by customer need. Technology leaders (such as a CTOs or.......\n",
      "---\n",
      "## Document 3: tiveness and efficiency of your operations.\n",
      "Successful evolution of operations is founded in: frequent small improvements; pro-\n",
      "viding safe environments and time to experiment, develop, and test improvements;\n",
      "and environments in which learning from failures is encouraged. Operations support\n",
      "for sandbox, development, test, and production environments, with increasing lev-\n",
      "el of operational controls, facilitates development and increases the predictability of\n",
      "successful results from changes deployed into production.\n",
      "Resources\n",
      "Refer to the following resources to learn more about our best practices for Opera-\n",
      "tional Excellence .\n",
      "Documentation\n",
      "•DevOps and AWS\n",
      "Whitepaper\n",
      "14.......\n",
      "---\n",
      "## Document 4: ArchivedAWS Well-Architected Framework\n",
      "The Five Pillars of the Framework\n",
      "Creating a software system is a lot like constructing a building. If the foundation is\n",
      "not solid, structural problems can undermine the integrity and function of the build-\n",
      "ing. When architecting technology solutions, if you neglect the ﬁve pillars of opera-\n",
      "tional excellence, security, reliability, performance efficiency, and cost optimization, it\n",
      "can become challenging to build a system that delivers on your expectations and re-\n",
      "quirements. Incorporating these pillars into your architecture will help you produce\n",
      "stable and efficient systems. This will allow you to focus on the other aspects of de-\n",
      "sign, such as functional requirements.\n",
      "Operational Excellence\n",
      "The Operational Excellence pillar includes the ability to support development and run\n",
      "workloads effectively, gain insight into their operations, and to continuously improve\n",
      "supporting processes and procedures to deliver business value........\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "relevant_documents = faiss.similarity_search_by_vector(query_embedding)\n",
    "context = \"\"\n",
    "print(f'{len(relevant_documents)} documents are fetched which are relevant to the query.')\n",
    "print('----')\n",
    "for i, rel_doc in enumerate(relevant_documents):\n",
    "    print(f'## Document {i+1}: {rel_doc.page_content}.......')\n",
    "    print('---')\n",
    "    context += rel_doc.page_content\n",
    "context = context.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9e423c-19d2-4d62-8271-332038785c1d",
   "metadata": {},
   "source": [
    "Now create a prompt template to trigger the model with above context from vector search. We specifically inform the model to answer only using the context provied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c9ecdbd-e4c5-4a1b-8db9-0d82390c6a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "        You are a helpful, polite, fact-based agent.\n",
    "        If you don't know the answer, just say that you don't know.\n",
    "        Please answer the following question using the context provided. \n",
    "\n",
    "        CONTEXT: \n",
    "        {context}\n",
    "        =========\n",
    "        QUESTION: {question} \n",
    "        ANSWER: \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c31b73a-cfaa-4d9c-915c-ca799c3fc0d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        You are a helpful, polite, fact-based agent.\n",
      "        If you don't know the answer, just say that you don't know.\n",
      "        Please answer the following question using the context provided. \n",
      "\n",
      "        CONTEXT: \n",
      "        can emerge that is driven by customer need. Technology leaders (such as a CTOs or development managers), carrying out Well-Architected reviews across all your work- loads will allow you to better understand the risks in your technology portfolio. Using this approach, you can identify themes across teams that your organization could ad- dress by mechanisms, training, or lunchtime talks where your principal engineers can share their thinking on specific areas with multiple teams. 3Working backward is a fundamental part of our innovation process. We start with the customer and what they want, and let that define and guide our efforts. 4ternet scale. We prefer to use data to define best practice, but we also use subject matter experts, like principal engineers, to set them. As principal engineers see new best practices emerge, they work as a community to ensure that teams follow them. In time, these best practices are formalized into our internal review processes, as well as into mechanisms that enforce compliance. The Well-Architected Framework is the customer-facing implementation of our internal review process, where we have cod- ified our principal engineering thinking across ﬁeld roles, like Solutions Architecture and internal engineering teams. The Well-Architected Framework is a scalable mecha- nism that lets you take advantage of these learnings. By following the approach of a principal engineering community with distributed ownership of architecture, we believe that a Well-Architected enterprise architecture can emerge that is driven by customer need. Technology leaders (such as a CTOs ortiveness and efficiency of your operations. Successful evolution of operations is founded in: frequent small improvements; pro- viding safe environments and time to experiment, develop, and test improvements; and environments in which learning from failures is encouraged. Operations support for sandbox, development, test, and production environments, with increasing lev- el of operational controls, facilitates development and increases the predictability of successful results from changes deployed into production. Resources Refer to the following resources to learn more about our best practices for Opera- tional Excellence . Documentation •DevOps and AWS Whitepaper 14ArchivedAWS Well-Architected Framework The Five Pillars of the Framework Creating a software system is a lot like constructing a building. If the foundation is not solid, structural problems can undermine the integrity and function of the build- ing. When architecting technology solutions, if you neglect the ﬁve pillars of opera- tional excellence, security, reliability, performance efficiency, and cost optimization, it can become challenging to build a system that delivers on your expectations and re- quirements. Incorporating these pillars into your architecture will help you produce stable and efficient systems. This will allow you to focus on the other aspects of de- sign, such as functional requirements. Operational Excellence The Operational Excellence pillar includes the ability to support development and run workloads effectively, gain insight into their operations, and to continuously improve supporting processes and procedures to deliver business value.\n",
      "        =========\n",
      "        QUESTION: What are the 5 pillars of well architected framework? \n",
      "        ANSWER: \n"
     ]
    }
   ],
   "source": [
    "prompt = template.format(context=context, question=query)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d41b64-49cf-4842-82f6-286bee678e3d",
   "metadata": {},
   "source": [
    "Invoke the endpoint to generate a response from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "678113c4-4c76-49ad-8ccb-095ad9a27529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d4ae283-0745-4849-b832-1a735bf06799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_model = smr_client.invoke_endpoint(\n",
    "    EndpointName=TEXT_GENERATION_MODEL_ENDPOINT_NAME,\n",
    "    Body=json.dumps(\n",
    "        {\"inputs\": prompt, \"parameters\": {\"max_new_tokens\": 500}}\n",
    "    ),\n",
    "    ContentType=\"application/json\",\n",
    ")\n",
    "response = json.loads(response_model[\"Body\"].read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7113187c-17a2-49a7-9443-e28e27934bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Security, 2. Reliability, 3. Performance, 4. Cost optimization, 5. Operational excellence.\n"
     ]
    }
   ],
   "source": [
    "print(response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c1b89-8e77-4dfb-a4ea-f279dcf70541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
